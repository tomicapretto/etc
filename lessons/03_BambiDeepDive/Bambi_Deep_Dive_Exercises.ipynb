{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "from bambi.plots import plot_cap\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use(\"intuitivebayes.mplstyle\")\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 120\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.spines.left\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Art-attack\n",
    "\n",
    "In the section \"The world's simplest model\" from \"Lesson 2: Regression Refresher\" we created the following visualization.\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/intercept_only_model_curve.png\" style=\"width:950px;\"/>\n",
    "</center>\n",
    "\n",
    "This allowed us to see the intercept-only model fits a flat line that is not affected by the values of the predictor. \n",
    "\n",
    "You're asked to reproduce this visualization, using the Bambi model we created in this lesson. Fortunately, you don't need to write a lot of code from scratch. Use the snippet from Lesson 2 and find the places where you need to change parameter names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've loaded the data for you\n",
    "fish_data = pd.read_csv(\"data/fish-market.csv\")\n",
    "fish_data[fish_data[\"Weight\"] > 0].reset_index(drop=True)\n",
    "fish_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Bambi model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reference Python Code\n",
    "\n",
    "```python\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "ax.scatter(x=data[\"Length1\"], y=data[\"Weight\"], alpha=0.6)\n",
    "ax.set(xlabel=\"Length (centimeters)\", ylabel=\"Weight (grams)\", title=\"Fish length vs weight\");\n",
    "\n",
    "for value in idata.posterior[\"β0\"].to_numpy().flatten()[::10]:\n",
    "    ax.axhline(value, color=\"C1\", alpha=0.2)\n",
    "\n",
    "β0_mean = idata.posterior[\"β0\"].to_numpy().mean()\n",
    "ax.axhline(β0_mean, color=\"C4\")\n",
    "\n",
    "handles = [\n",
    "    Line2D([], [], label=\"Observations\", lw=0, marker=\"o\", color=\"C0\", alpha=0.6),\n",
    "    Line2D([], [], label=\"Posterior draws\", lw=2, color=\"C1\"),\n",
    "    Line2D([], [], label=\"Posterior mean\", lw=2, color=\"C4\"),\n",
    "]\n",
    "ax.legend(handles=handles, loc=\"upper left\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Mastering `plot_cap()`\n",
    "\n",
    "In this exercise you have to work with the fish data and the model we created in the \"Transformations in Bambi\" section. More concretely, you need to build the following model\n",
    "\n",
    "```python\n",
    "model = bmb.Model(\"log(Weight) ~ 1 + log(Length1)\", data)\n",
    "```\n",
    "Notice you need to import the data to solve this exercise. Then create and fit the model mentioned above, and use `plot_cap()` with `Length1` as the variable for the horizontal axis.\n",
    "\n",
    "```python\n",
    "plot_cap(model, idata, \"Length1\")\n",
    "```\n",
    "\n",
    "Answer the following questions\n",
    "\n",
    "* What do you see?\n",
    "    * Is it a straight line?\n",
    "    * Why?\n",
    "* What is the scale of the variables in the horizontal and the vertical axis? Consider they're used with an inline transformation in the model.\n",
    "    * Why?\n",
    "* How can you put both variables in the transformed scale?\n",
    "* And how you put everything on the untransformed scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Bambi model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cap plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Advanced operators\n",
    "\n",
    "In the section \"Transformations in Bambi\" we showed that some custom operations needed to be written using a particular syntax. In this exercise you're going to experiment a little with with these operations to see how they work in practice. The goal here is not to arrive to a \"correct\" answer, but to see what are the different results when we try different formulas and trying to understand what's going on. Use the following simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1211)\n",
    "size = 100\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"response\": rng.normal(loc=5, scale=0.5, size=size),\n",
    "        \"x\": rng.normal(loc=10, scale=2, size=size),\n",
    "        \"y\": rng.normal(size=size),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 1\n",
    "Use the following formulas and explain what's happening\n",
    "\n",
    "* `\"response ~ x ** 100\"`\n",
    "* `\"response ~ x / y\"`\n",
    "* `\"response ~ (x + y) ** 2\"`\n",
    "\n",
    "It's fine if you can only describe what you see. At this point you're not expected to be an expert in formula notation. We'll cover more advanced stuff later in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Try this\n",
    "* `\"response ~ x / 100`\"\n",
    "\n",
    "You'll see an exception, this is expected. We want you to get familiar with what it looks like when Bambi formula syntax fails, and give you a preview to later lessons in the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "What is the difference between `\"response ~ x + y\"` and `\"response ~ I(x + y)\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Time to experiment\n",
    "\n",
    "In the \"Parameter identifiability\" section we simulated some data to grasp what non-identifiability means using a controlled scenario. The code we used is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1234)\n",
    "b0, b1 = 0.5, 2.5\n",
    "x = np.linspace(0, 3, num=50)\n",
    "noise = rng.normal(scale=0.5, size=50)\n",
    "y = b0 + b1 * x + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we created the following PyMC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    b0 = pm.Normal(\"b0\", sigma=0.5)\n",
    "    b1 = pm.Normal(\"b1\")\n",
    "    b2 = pm.Normal(\"b2\")\n",
    "    mu = b0 + b1 * x + b2 * x\n",
    "    sigma = pm.HalfNormal(\"sigma\" ,sigma=0.5)\n",
    "    pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to have you run several experiments to understand how parameter non-identifiablity affects sampling times and the quality of the draws obtained. You are asked to\n",
    "\n",
    "* Repeat this experiment with different sample sizes.\n",
    "    * Use $n=500$ \n",
    "    * Use $n=2000$\n",
    "* Explore the posterior of the slopes\n",
    "* Do you get any warnings?\n",
    "* Explore the correlation between $b_1$ and $b_2$. \n",
    "    * Does it improve with more data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the correct model, with a single slope\n",
    "\n",
    "```python\n",
    "with pm.Model() as good_model:\n",
    "    b0 = pm.Normal(\"b0\", sigma=0.5)\n",
    "    b1 = pm.Normal(\"b1\")\n",
    "    mu = b0 + b1 * x\n",
    "    sigma = pm.HalfNormal(\"sigma\" ,sigma=0.5)\n",
    "    pm.Normal(\"y\", mu=mu, sigma=sigma, observed=y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit it using $n=500$ and $n=2000$, as done previously\n",
    "* Compare the sampling speed with the previous model\n",
    "    * What can you conclude about the effects of parameter correlations in sampling speed?\n",
    "* Can you recover the true slope?\n",
    "* Do you get any warnings?\n",
    "* Also explore the correlation between model parameters. \n",
    "    * What can you conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you're asked to reproduce the flawed model in Bambi. To do so, you need to use the formula `\"y ~ x + x\"`. \n",
    "\n",
    "* What happens?\n",
    "* Why do you think it works that way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: What if...\n",
    "\n",
    "In the section \"An end to end trip with Bambi\" we computed the $R^2$ coefficient of the following model\n",
    "\n",
    "```python\n",
    "model = bmb.Model(\"log(Weight) ~ 0 + Species + log(Length1):Species\", data)\n",
    "```\n",
    "\n",
    "We got an $R^2$ equal to 0.984, which is very high. \n",
    "\n",
    "In this exercise you're asked to use the other numerical predictors in the dataset in place of `Length1`, compute the $R^2$ of those models, and compare to what we got with `Length1`.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "You have to create two extra models. One using `Height` and other using `Width` as predictors. You can keep the same strcuture of varying intercepts and varying slopes. \n",
    "\n",
    "**Optional**\n",
    "\n",
    "Combine two or more of the numerical predictors, compute the $R^2$ coefficient, and compare with the previous models. Does adding more numerical predictors improve $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Interaction effects\n",
    "\n",
    "In this exercise we're going to learn more about interaction effects. In the section \"The full model\" we covered that the different `log(Length)` slopes per `Species` is an interaction between `log(Length)` and `Species`. More generally, this is an interaction between a numeric and a categorical variable. The result was as many slopes as species in our dataset.\n",
    "\n",
    "Now we're going to exercise another type of interaction, between two numerics, which is the first case in the following diagram.\n",
    "\n",
    "<center>\n",
    "  <img src=\"imgs/interaction_symbol.png\" style=\"width:950px\"; />\n",
    "</center>\n",
    "\n",
    "We expect this to give us a single new slope, which is multiplied by the product of the two numerical covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars_data = pd.read_csv(\"data/mtcars.csv\")\n",
    "mtcars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973--74 models). The following is a description of the variables:\n",
    "\n",
    "* `mpg`: Miles/(US) gallon\n",
    "* `cyl`: Number of cylinders\n",
    "* `disp`: Displacement (cu.in.)\n",
    "* `hp`: Gross horsepower\n",
    "* `drat`: Rear axle ratio\n",
    "* `wt`: Weight (1000 lbs)\n",
    "* `qsec`: 1/4 mile time\n",
    "* `vs`: Engine (0 = V-shaped, 1 = straight)\n",
    "* `am`: Transmission (0 = automatic, 1 = manual)\n",
    "* `gear`: Number of forward gears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The models\n",
    "\n",
    "We're going to us the Gross horsepower (`hp`) and the Weight (`wt`) to predict the fuel consumption in Miles per US gallon (`mpg`).\n",
    "\n",
    "**Main effects model**\n",
    "\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + \\beta_1 \\text{hp} + \\beta_2 \\text{wt} + \\varepsilon\n",
    "$$\n",
    "\n",
    "**Interaction effects model**\n",
    "\n",
    "$$\n",
    "\\text{mpg} = \\beta_0 + \\beta_1 \\text{hp} + \\beta_2 \\text{wt} + \\beta_3 \\text{hp} \\cdot \\text{wt}  + \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The questions\n",
    "\n",
    "* Build and fit the main effects model\n",
    "* Build and fit the model with the interaction effects\n",
    "* Explore the posterior of both models\n",
    "    * What can you conclude about the coefficient of the interaction effect?\n",
    "* Use `plot_cap()` to compare the fitted curves\n",
    "    * Map `hp` to the horizontal axis and `wt` to the color or the panel.\n",
    "    * Can you describe how the interaction affects the fitted curves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: A model with many predictors \n",
    "\n",
    "This is the continuation of Exercise 4 from the previous lesson, where we worked with the construction problem. Now we're going to use all the predictors, not just cement and water, to predict the concrete strength. \n",
    "\n",
    "The goal of this exercise is to learn how scaling of the predictors may help our sampler to work faster. Also, it challenges you to come up with an alternative that will prevent our model from giving negative predictions, a problem we already detected in Exercise 4 from the previous lesson.\n",
    "\n",
    "If you want to refresh your knowledge about the `scale()` transform, revisit the section \"Transformations in Bambi\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "The team has already tested more than a thousand samples ([source](https://archive.ics.uci.edu/ml/datasets/concrete+compressive+strength)) and the following variables were measured and recorded\n",
    "\n",
    "* **cement** - Portland cement in kg/m3\n",
    "* **slag** - Blast furnace slag in kg/m3\n",
    "* **fly_ash** - Fly ash in kg/m3\n",
    "* **water** - Water in liters/m3\n",
    "* **superplasticizer** - Superplasticizer additive in kg/m3\n",
    "* **coarse_aggregate** - Coarse aggregate (gravel) in kg/m3\n",
    "* **fine_aggregate** - Fine aggregate (sand) in kg/m3\n",
    "* **age** - Age of the sample in days\n",
    "* **strength** - Concrete compressive strength in megapascals (MPa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data = pd.read_csv(\"data/concrete.csv\")\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_new = pd.DataFrame(\n",
    "    {\n",
    "        \"cement\": [520, 300, 400],\n",
    "        \"slag\": [100, 50, 70],\n",
    "        \"fly_ash\": [120, 40, 90],\n",
    "        \"water\": [228, 160, 200],\n",
    "        \"superplasticizer\": [22, 16, 20],\n",
    "        \"coarse_aggregate\": [1000, 800, 900],\n",
    "        \"fine_aggregate\": [825, 650, 775],\n",
    "        \"age\": [48, 128, 80],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The models\n",
    "\n",
    "Since we're using all the predictors, the formulas are quite big. We could build them using Python, but for the sake of clarity we prefer to just write them down.\n",
    "\n",
    "**Unscaled model**\n",
    "\n",
    "```python\n",
    "formula = \"strength ~ cement + slag + fly_ash + water + superplasticizer + coarse_aggregate + fine_aggregate + age\"\n",
    "```\n",
    "\n",
    "**Scaled model**\n",
    "\n",
    "```python\n",
    "formula = \"strength ~ scale(cement) + scale(slag) + scale(fly_ash) + scale(water) + scale(superplasticizer) + scale(coarse_aggregate) + scale(fine_aggregate) + scale(age)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The questions\n",
    "\n",
    "* Build and fit the unscaled model\n",
    "* Build and fit the scaled model\n",
    "* Compare sampling times\n",
    "* Predict the weight of the three samples in the data frame `concrete_data_new` using both models\n",
    "    * Do predictions differ between models?\n",
    "    * Why?\n",
    "* Plot the posterior predictive distribution\n",
    "    * If the model predicts negative strenghts, propose a model that fixes this problem.\n",
    "    * Fit the new model and explore the posterior predictive distribution again.\n",
    "    * What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "The data for this exercise originally comes from\n",
    "\n",
    "* I-Cheng Yeh, \"Modeling of strength of high performance concrete using artificial neural networks,\" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "96b52e1d985b6c457db8356caeb4e1b2f8f20b187e2d2aa9e312ebd461d4cda7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
